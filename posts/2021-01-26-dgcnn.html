<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh" xml:lang="zh">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="last_modified" content="2021-01-28T11:28:40Z" />
  <meta name="published" content="Jan 26, 2021" />
  <title>Dynamic Graph CNN:动态图卷积</title>
  <link rel="stylesheet" href="/static/style.css" />
  <link rel="stylesheet" href="/static/syntax-highlighting.css" />
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link rel="icon" href="/static/favicon.ico" type="image/x-icon"/> <link rel="shortcut icon" href="/static/favicon.ico" type="image/x-icon" />
  <meta name="author" content="Yanjie Ze">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date());
  gtag('config', 'UA-116308654-1'); </script>
</head>
<body>
<a id="return" href="/"> <img src="/static/logo.png" style="width:25%;float:right"> </a>
<header id="title-block-header">
<h1 class="title">Dynamic Graph CNN:动态图卷积</h1>
<p class="date">Jan 26, 2021</p>
</header>
<h3 id="阅读论文dynamic-graph-cnn-for-learning-on-point-clouds">阅读论文：Dynamic Graph CNN for Learning on Point Clouds</h3>
<h1 id="一介绍">一、介绍</h1>
<p>原文中提到，为了解决<strong>Pointnet忽视点之间的几何关系</strong>的问题，提出了EdgeConv，可以抓住局部几何结构并且保持排列不变性。</p>
<p>总结一下这篇文章的主要贡献： 1. 提出了EdgeConv，为了更好地获得局部几何特征，并保持排列不变性。</p>
<ol start="2" type="1">
<li><p>展现了这个模型可以通过<strong>动态地更新层与层之间的图关系</strong>来从语义上组合点。</p></li>
<li><p>证明了EdgeConv可以聚合进各种目前存在的点云处理方法。</p></li>
<li><p>展现了EdgeConv可以达到SOTA的效果。</p></li>
<li><p>提供了代码。</p></li>
</ol>
<h1 id="二相关工作">二、相关工作</h1>
<h2 id="hand-crafted-features">Hand-Crafted Features</h2>
<p>什么是hand-crafted features？ &gt; “Hand Crafted” features refer to properties derived using various algorithms using the information present in the image itself. For example, two simple features that can be extracted from images are edges and corners. A basic edge detector algorithm works by finding areas where the image intensity “suddenly” changes.</p>
<p>就是角点和边缘之类的特征吧。</p>
<p>Hand-crafted features可以分为两类：extrinsic和intrinsic。</p>
<h2 id="deep-learning-on-geometry">Deep Learning on geometry</h2>
<p>与图像不同，几何数据没有网格，需要建立新的结构。</p>
<p>提到了几何生成模型geometric generative models，比如VAE和GAN。</p>
<h1 id="三我们的方法">三、我们的方法</h1>
<p>使用局部几何结构，通过组建一个局部邻接图，使用类似与卷积的操作对边进行操作，借鉴图神经网络的方法。</p>
<p>这种叫EdgeConv的方法，有着平移不变性和非局部性。</p>
<p>与图卷积网络不一样的是，这里的图不是固定的，而是在每层网络后动态更新。</p>
<p>什么是图卷积神经网络？：<a href="https://zhuanlan.zhihu.com/p/71200936">何时能懂你的心——图卷积神经网络（GCN）</a></p>
<h2 id="edge-convolution">（1）Edge Convolution</h2>
<center>
<img src="../imgs/formula5.png" alt="formula">
</center>
<p>公式1的含义是：对一个点的相邻边做一个类似与卷积的函数操作，把多条边的信息提炼成一个特征。h为edge function，方框为aggregation operation，x_i表示第i个顶点，x_j表示该点周围的第j个点。下图为该操作的形象过程。</p>
<center>
<img src="../imgs/edgeconv.png" alt="edgeconv">
</center>
<p>edgeconv函数h的多个选择： 1. 类似于对二维图像的卷积</p>
<ol start="2" type="1">
<li><p>类似于Pointnet的只关注自身</p></li>
<li><p>结合相邻点、该点与相邻点的距离。</p></li>
<li><p>相减</p></li>
<li><p>对称边缘函数（在该论文中使用）</p></li>
</ol>
方法5既捕捉了全局特征，也捕捉了局部特征，在论文中使用。 其形式是：
<center>
<img src="../imgs/formula13.png" alt="formula">
</center>
更具体一点的公式：
<center>
<img src="../imgs/formula6.png" alt="formula">
</center>
<h2 id="dynamic-graph-update">（2）Dynamic graph update</h2>
<p>在每一层操作后，使用最近邻算法重新计算图（在特征空间中），因此叫该网络为Dynamic Graph CNN。</p>
<p>此外，该网络学习如何构造每个层中使用的图G，而不是将其作为在评估网络之前构造的固定常数。在具体的实现中，计算了特征空间中的成对距离矩阵，然后对每个单点取最近的k个点。</p>
<h2 id="properties">（3）Properties</h2>
<p>排列不变性：由于max这种对称性运算的存在。</p>
<p>平移不变性：部分具有平移不变性。</p>
<h2 id="comparison-to-existing-methods">（4）Comparison to existing methods</h2>
DGCNN和PointNet、Graph CNN关系比较大，不同之处在下图中体现。
<center>
<img src="../imgs/dgcnncomp.png" alt="comp">
</center>
<p>其中g为Gaussian Kernel。</p>
<h1 id="四核心代码">四、核心代码</h1>
<p>KNN的实现</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="kw">def</span> knn(x, k):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true"></a>    inner <span class="op">=</span> <span class="op">-</span><span class="dv">2</span><span class="op">*</span>torch.matmul(x.transpose(<span class="dv">2</span>, <span class="dv">1</span>), x)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true"></a>    xx <span class="op">=</span> torch.<span class="bu">sum</span>(x<span class="op">**</span><span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true"></a>    pairwise_distance <span class="op">=</span> <span class="op">-</span>xx <span class="op">-</span> inner <span class="op">-</span> xx.transpose(<span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true"></a> </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true"></a>    idx <span class="op">=</span> pairwise_distance.topk(k<span class="op">=</span>k, dim<span class="op">=-</span><span class="dv">1</span>)[<span class="dv">1</span>]   <span class="co"># (batch_size, num_points, k)</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true"></a>    <span class="cf">return</span> idx</span></code></pre></div>
<p>获得graph feature</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a><span class="kw">def</span> get_graph_feature(x, k<span class="op">=</span><span class="dv">20</span>, idx<span class="op">=</span><span class="va">None</span>):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>    batch_size <span class="op">=</span> x.size(<span class="dv">0</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a>    num_points <span class="op">=</span> x.size(<span class="dv">2</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a>    x <span class="op">=</span> x.view(batch_size, <span class="op">-</span><span class="dv">1</span>, num_points)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a>    <span class="cf">if</span> idx <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a>        idx <span class="op">=</span> knn(x, k<span class="op">=</span>k)   <span class="co"># (batch_size, num_points, k)</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a>    device <span class="op">=</span> torch.device(<span class="st">&#39;cuda&#39;</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true"></a>    idx_base <span class="op">=</span> torch.arange(<span class="dv">0</span>, batch_size, device<span class="op">=</span>device).view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>)<span class="op">*</span>num_points</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true"></a>    idx <span class="op">=</span> idx <span class="op">+</span> idx_base</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true"></a>    idx <span class="op">=</span> idx.view(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true"></a> </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true"></a>    _, num_dims, _ <span class="op">=</span> x.size()</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true"></a>    x <span class="op">=</span> x.transpose(<span class="dv">2</span>, <span class="dv">1</span>).contiguous()   <span class="co"># (batch_size, num_points, num_dims)  -&gt; (batch_size*num_points, num_dims) #   batch_size * num_points * k + range(0, batch_size*num_points)</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true"></a>    feature <span class="op">=</span> x.view(batch_size<span class="op">*</span>num_points, <span class="op">-</span><span class="dv">1</span>)[idx, :]</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true"></a>    feature <span class="op">=</span> feature.view(batch_size, num_points, k, num_dims) </span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true"></a>    x <span class="op">=</span> x.view(batch_size, num_points, <span class="dv">1</span>, num_dims).repeat(<span class="dv">1</span>, <span class="dv">1</span>, k, <span class="dv">1</span>)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true"></a>    </span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true"></a>    feature <span class="op">=</span> torch.cat((feature<span class="op">-</span>x, x), dim<span class="op">=</span><span class="dv">3</span>).permute(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>).contiguous()</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true"></a>  </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true"></a>    <span class="cf">return</span> feature</span></code></pre></div>
<p>Deep Graph CNN的实现</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a><span class="kw">class</span> DGCNN(nn.Module):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, args, output_channels<span class="op">=</span><span class="dv">40</span>):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a>        <span class="bu">super</span>(DGCNN, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a>        <span class="va">self</span>.args <span class="op">=</span> args</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a>        <span class="va">self</span>.k <span class="op">=</span> args.k</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a>        </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a>        <span class="va">self</span>.bn1 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">64</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a>        <span class="va">self</span>.bn2 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">64</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true"></a>        <span class="va">self</span>.bn3 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">128</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true"></a>        <span class="va">self</span>.bn4 <span class="op">=</span> nn.BatchNorm2d(<span class="dv">256</span>)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true"></a>        <span class="va">self</span>.bn5 <span class="op">=</span> nn.BatchNorm1d(args.emb_dims)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Sequential(nn.Conv2d(<span class="dv">6</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true"></a>                                   <span class="va">self</span>.bn1,</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true"></a>                                   nn.LeakyReLU(negative_slope<span class="op">=</span><span class="fl">0.2</span>))</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Sequential(nn.Conv2d(<span class="dv">64</span><span class="op">*</span><span class="dv">2</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true"></a>                                   <span class="va">self</span>.bn2,</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true"></a>                                   nn.LeakyReLU(negative_slope<span class="op">=</span><span class="fl">0.2</span>))</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true"></a>        <span class="va">self</span>.conv3 <span class="op">=</span> nn.Sequential(nn.Conv2d(<span class="dv">64</span><span class="op">*</span><span class="dv">2</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true"></a>                                   <span class="va">self</span>.bn3,</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true"></a>                                   nn.LeakyReLU(negative_slope<span class="op">=</span><span class="fl">0.2</span>))</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true"></a>        <span class="va">self</span>.conv4 <span class="op">=</span> nn.Sequential(nn.Conv2d(<span class="dv">128</span><span class="op">*</span><span class="dv">2</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true"></a>                                   <span class="va">self</span>.bn4,</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true"></a>                                   nn.LeakyReLU(negative_slope<span class="op">=</span><span class="fl">0.2</span>))</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true"></a>        <span class="va">self</span>.conv5 <span class="op">=</span> nn.Sequential(nn.Conv1d(<span class="dv">512</span>, args.emb_dims, kernel_size<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>),</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true"></a>                                   <span class="va">self</span>.bn5,</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true"></a>                                   nn.LeakyReLU(negative_slope<span class="op">=</span><span class="fl">0.2</span>))</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true"></a>        <span class="va">self</span>.linear1 <span class="op">=</span> nn.Linear(args.emb_dims<span class="op">*</span><span class="dv">2</span>, <span class="dv">512</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true"></a>        <span class="va">self</span>.bn6 <span class="op">=</span> nn.BatchNorm1d(<span class="dv">512</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true"></a>        <span class="va">self</span>.dp1 <span class="op">=</span> nn.Dropout(p<span class="op">=</span>args.dropout)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true"></a>        <span class="va">self</span>.linear2 <span class="op">=</span> nn.Linear(<span class="dv">512</span>, <span class="dv">256</span>)</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true"></a>        <span class="va">self</span>.bn7 <span class="op">=</span> nn.BatchNorm1d(<span class="dv">256</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true"></a>        <span class="va">self</span>.dp2 <span class="op">=</span> nn.Dropout(p<span class="op">=</span>args.dropout)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true"></a>        <span class="va">self</span>.linear3 <span class="op">=</span> nn.Linear(<span class="dv">256</span>, output_channels)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true"></a>        batch_size <span class="op">=</span> x.size(<span class="dv">0</span>)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true"></a>        x <span class="op">=</span> get_graph_feature(x, k<span class="op">=</span><span class="va">self</span>.k)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true"></a>        x <span class="op">=</span> <span class="va">self</span>.conv1(x)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true"></a>        x1 <span class="op">=</span> x.<span class="bu">max</span>(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">False</span>)[<span class="dv">0</span>]</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true"></a></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true"></a>        x <span class="op">=</span> get_graph_feature(x1, k<span class="op">=</span><span class="va">self</span>.k)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true"></a>        x <span class="op">=</span> <span class="va">self</span>.conv2(x)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true"></a>        x2 <span class="op">=</span> x.<span class="bu">max</span>(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">False</span>)[<span class="dv">0</span>]</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true"></a></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true"></a>        x <span class="op">=</span> get_graph_feature(x2, k<span class="op">=</span><span class="va">self</span>.k)</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true"></a>        x <span class="op">=</span> <span class="va">self</span>.conv3(x)</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true"></a>        x3 <span class="op">=</span> x.<span class="bu">max</span>(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">False</span>)[<span class="dv">0</span>]</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true"></a></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true"></a>        x <span class="op">=</span> get_graph_feature(x3, k<span class="op">=</span><span class="va">self</span>.k)</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true"></a>        x <span class="op">=</span> <span class="va">self</span>.conv4(x)</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true"></a>        x4 <span class="op">=</span> x.<span class="bu">max</span>(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">False</span>)[<span class="dv">0</span>]</span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true"></a></span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true"></a>        x <span class="op">=</span> torch.cat((x1, x2, x3, x4), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true"></a></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true"></a>        x <span class="op">=</span> <span class="va">self</span>.conv5(x)</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true"></a>        x1 <span class="op">=</span> F.adaptive_max_pool1d(x, <span class="dv">1</span>).view(batch_size, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true"></a>        x2 <span class="op">=</span> F.adaptive_avg_pool1d(x, <span class="dv">1</span>).view(batch_size, <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true"></a>        x <span class="op">=</span> torch.cat((x1, x2), <span class="dv">1</span>)</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true"></a></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true"></a>        x <span class="op">=</span> F.leaky_relu(<span class="va">self</span>.bn6(<span class="va">self</span>.linear1(x)), negative_slope<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true"></a>        x <span class="op">=</span> <span class="va">self</span>.dp1(x)</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true"></a>        x <span class="op">=</span> F.leaky_relu(<span class="va">self</span>.bn7(<span class="va">self</span>.linear2(x)), negative_slope<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true"></a>        x <span class="op">=</span> <span class="va">self</span>.dp2(x)</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true"></a>        x <span class="op">=</span> <span class="va">self</span>.linear3(x)</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true"></a>        <span class="cf">return</span> x</span></code></pre></div>
<a style="color:black;font-size:2em;float:right;margin-right:30px;margin-bottom:40px;" href="../">[Return to the homepage]</a>
<script>
var code_blocks = document.querySelectorAll("pre.sourceCode");
code_blocks.forEach(function(block) {
  block.classList.add("numberSource");
  block.classList.add("numberLines");
});
</script>
</body>
</html>
