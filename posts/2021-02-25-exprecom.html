<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="zh" xml:lang="zh">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="last_modified" content="2021-02-27T09:32:18Z" />
  <meta name="published" content="Feb 25, 2021" />
  <title>Explainable Recommendation: Information Source</title>
  <link rel="stylesheet" href="/static/style.css" />
  <link rel="stylesheet" href="/static/syntax-highlighting.css" />
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link rel="icon" href="/static/favicon.ico" type="image/x-icon"/> <link rel="shortcut icon" href="/static/favicon.ico" type="image/x-icon" />
  <meta name="author" content="Yanjie Ze">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date());
  gtag('config', 'UA-116308654-1'); </script>
</head>
<body>
<a id="return" href="/"> <img src="/static/logo.png" style="width:25%;float:right"> </a>
<header id="title-block-header">
<h1 class="title">Explainable Recommendation: Information Source</h1>
<p class="date">Feb 25, 2021</p>
</header>
<p>model-intrinsic / model-agnostic: 可类比成人类做决定，是先有理由再做决定（model-intrinsic），还是先做决定再想理由（model-agnostic）。</p>
<h1 id="一历史纵览">一、历史纵览</h1>
<h2 id="早期content-basedcollaborative-filtering-based">早期：content based，collaborative filtering based</h2>
<p>content based比较直观，提供cintent feature作为推荐的理由。</p>
<p>user-based CF将user作为vector来预测缺失的值。</p>
<p>item-based CF将item作为vector，来预测是否喜欢新的item。</p>
<p>CF是可以解释的，但是比起content-based来说缺乏explain。</p>
<p>后来，CF结合latent factor model（LFM）又获得成功，但是latent factor的解释性不好。</p>
<h2 id="中期explainable-recommendation-system的提出">中期：Explainable Recommendation System的提出</h2>
<p>Explicit Factor Model把潜在的信息用确定的特征来解释。</p>
<p>近年来深度学习在这个领域也有应用，但是否真正有提升，还有待商榷。</p>
<h2 id="现在将问题分成两个维度">现在：将问题分成两个维度</h2>
<p>一是information source和display style，二是生成explanation的model。</p>
<p>值得注意的是，尽管information source和display style这两者概念有所区分，但是在这个问题中由于两者存在一定的关系，可以近似等同为一体。</p>
下表为近年来一些研究的模型方法与解释方式的关系表格。
<center>
<img src="../imgs/table1.jpg">
</center>
<h2 id="解释性与高效性的trade-off">解释性与高效性的trade off</h2>
<p>两者似乎不可兼得。</p>
<p>但是，在使用deep representation learning的模型中，解释性和高效性都很好。</p>
<h2 id="explainability-and-interpretability">Explainability and Interpretability</h2>
<p>可解释性。</p>
<h1 id="二information-source">二、Information Source</h1>
<blockquote>
<p>An explanation is a piece of information displayed to users, explaining why a particular item is recommended.</p>
</blockquote>
<p>比如： 1. textual sentence 2. topical word cloud 3. visually explainable recommendation 4. a list of freinds who also like 5. statistical histograms/pie charts</p>
常见的几种如下图所示：
<center>
<img src="../imgs/recom.png">
</center>
<h2 id="relevant-user-or-item-explanation">(1)Relevant User or Item Explanation</h2>
<p>relevant user explanation：展示其他user的评价情况（打分）来作为推荐理由。基于此，发展出social friend推荐。</p>
<p>relevant item explanation：通过以前使用过的产品，推荐相似的物品。</p>
<p>相似物品这种解释比较intuitive。</p>
<h2 id="feature-based-explanation">(2)Feature-based Explanation</h2>
<p>和content-based比较接近。</p>
<p>一种是对item的feature进行分析。尽量提供和user比较匹配的特征。比如把电影用很多tag标记，user有prefer的tag，两者进行匹配，利用tag进行解释。</p>
<p>还有一种是user demographic feature，比如age，gender，residence location。利用user自身的特征与相似人群匹配，利用这些feature进行解释。</p>
<h2 id="opinion-based-explanation">(3)Opinion-based Explanation</h2>
<p>分为aspect-level和sentence-level的，主要讲aspect-level。</p>
<p>这种方法和feature-based很像，但是不同之处在于：aspect是不能直接获得的，是推荐系统学出来的（比如从reviews）。</p>
<p>从review提取aspect-sentiment，用到sentiment analysis。</p>
<h2 id="sentence-explanation">(4)Sentence Explanation</h2>
<p>主要分为template-based和generation-based。</p>
<p>template-based的要学feature，填入template。</p>
<p>NLG的方法：LSTM，adversarial seq2seq等。</p>
<p>许多生成exlpanation的方法依赖于user的review来训练，但是review的噪声是很大的。因此处理的方法有：hierarchical sequence-to-sequence model（auto-denoising），提取有效数据，等等。 ## (5)Visual Explanation 可以通过对图片的某一部分高亮来表示user感兴趣的部分。</p>
<p>比如用attention来获得user关注的区域。</p>
下图是具体例子。
<center>
<img src="../imgs/recom.png">
</center>
<blockquote>
<p>In general, the research on visually explainable recommendation is still at its initial stage.</p>
</blockquote>
<h2 id="social-explanation">(6)Social Explanation</h2>
<p>比如facebook会根据共同好友推荐新好友，或推荐好友们都喜欢的东西。</p>
<p>但是，这与user自身的喜好不一定有关联。结合user自身与好友的喜好可以推荐出novelty的东西。</p>
<h2 id="final个人小结">(Final)个人小结</h2>
<p>从模型的逻辑上分，model-intrinsic or model-agnostic。可类比成人类做决定，是先有理由再做决定（model-intrinsic），还是先做决定再想理由（model-agnostic）。</p>
<p>从内容的形式上分，有文字的和图片的，文字的这种比较常见，图片的做的不多。（个人感觉用attention关注图片上的某一区域来进行推荐有一点牵强）</p>
<p>对于推荐文字的内容可以细分，比如：</p>
<ol type="1">
<li>直接用NLG模型，从所有用户的review中生成explanation。</li>
<li>人为发现数据中的feature然后制定，进行explain（可以填入template）</li>
<li>用网络学习feature，然后用sentiment analysis之类的nlp分析，然后explain（可以填入template）</li>
<li>把用户社交圈的喜好倾向作为依据进行explain。</li>
<li>根据用户个人喜欢（preference）作为推荐依据，生成explain。（最基本的一种）</li>
</ol>
<p>这其中有的可以是model- intrinsic，有的可以是model- agnostic，没有特意强调。</p>
<a style="color:black;font-size:2em;float:right;margin-right:30px;margin-bottom:40px;" href="../">[Return to the homepage]</a>
<script>
var code_blocks = document.querySelectorAll("pre.sourceCode");
code_blocks.forEach(function(block) {
  block.classList.add("numberSource");
  block.classList.add("numberLines");
});
</script>
</body>
</html>
