---
title: "Collaborative Multi-Agent Dialogue Model Training Via Reinforcement Learning"
date: Feb 19, 2021
---
# 零、总体模型
总体框架：2个agent（1个information seeker，1个information provider）。

每个agent：Language Understanding -> Dialogue Policy -> Language Generation

# 一、Natrual Language Understanding

sentence => intent + tag：slot

多个intent，转化为多分类问题。

特殊的intent：request，它的slot为新的类。

数据增强方面：将intent和tag拼接作为新的tag，来给slot加上。

总体的模型：一个卷积encoder，两个decoder（一个intent分类器，一个slot tagger）。

评价指标：F1 measure

# 二、Dialogue Policy Learning
训两个agent，seeker和provider。

seeker的state：偏好（目标），provider提供的信息。

provider的state：seeker要求的信息和提供的限制

reward： It assigns a positive value on successful task completion (restaurant provided matches the seeker’s goal, and all seeker’s requests are answered), a negative value otherwise, and a small negative value for each dialogue turn to favor shorter interactions. However, a seeker is penalised for each request in the goal that is not expressed, and a provider is penalised for each request that is unanswered.

## (1)WoLF-PHC
